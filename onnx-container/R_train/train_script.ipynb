{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1ff53b-b057-4fd8-a3b3-c77e68ce81ff",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.setenv(TORCH_HOME = Sys.getenv(\"TORCH_HOME\")) \n",
    "Sys.setenv(TORCH_INSTALL_CUDA = \"1\") \n",
    "library(torch) \n",
    "cuda_is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715936d9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘coro’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    collect\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘yardstick’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:readr’:\n",
      "\n",
      "    spec\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(torch)\n",
    "library(tibble)\n",
    "library(dplyr)\n",
    "library(psych)   \n",
    "library(coro)\n",
    "library(readr)\n",
    "library(yardstick)\n",
    "library(progress)\n",
    "library(cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a294b49",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_path <- \"/scratch/tmp/ssureshk/torchdata\"\n",
    "RESULTS_DIR   <- \"training_logs_r\"\n",
    "dir.create(RESULTS_DIR, showWarnings = FALSE)\n",
    "BATCH_SIZE <- 1024\n",
    "EPOCHS <- 11\n",
    "LEARNING_RATE <- 2.38e-4\n",
    "WEIGHT_DECAY <- 5.18e-5\n",
    "DROPOUT_RATE  <- 0.182039\n",
    "N_CLASSES     <- 9\n",
    "MODEL_NAME    <- \"TempCNN\"\n",
    "class_names <- paste0(\"Class_\", 1:N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75f6a29",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n"
     ]
    }
   ],
   "source": [
    "device <- if (cuda_is_available()) torch_device(\"cuda\") else torch_device(\"cpu\")\n",
    "cat(\"Using device:\", device$type, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafe614a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensors...\n"
     ]
    }
   ],
   "source": [
    "cat(\"Loading tensors...\\n\")\n",
    "X <- torch_load(file.path(data_path, \"X_combined.pt\"))  # keep on CPU\n",
    "y <- torch_load(file.path(data_path, \"y_combined.pt\"))  # keep on CPU\n",
    "\n",
    "# Sanity checks\n",
    "stopifnot(X$dim() == 3, X$size(2) == 13, X$size(3) == 45)\n",
    "stopifnot(y$dim() == 1, y$size(1) == X$size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45703a5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "  X: 485649 x 13 x 45 \n",
      "  y: 485649 \n"
     ]
    }
   ],
   "source": [
    "cat(\"Data shapes:\\n\")\n",
    "cat(\"  X:\", paste(X$shape, collapse = \" x \"), \"\\n\")\n",
    "cat(\"  y:\", paste(y$shape, collapse = \" x \"), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61dd9234",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 485649 samples\n",
      "Batches per epoch: 475 \n"
     ]
    }
   ],
   "source": [
    "Bre_Dataset <- dataset(\n",
    "  name = \"BreizhPTDataset\",\n",
    "  initialize = function(X, y) {\n",
    "    self$X <- X\n",
    "    self$y <- y\n",
    "  },\n",
    "  .getitem = function(i) {\n",
    "    # Coerce index to a base R integer scalar\n",
    "    if (inherits(i, \"torch_tensor\")) {\n",
    "      i <- as.integer(as_array(i))\n",
    "    } else {\n",
    "      i <- as.integer(i)\n",
    "    }\n",
    "    if (length(i) != 1L) {\n",
    "      stop(\"Dataset .getitem expected a single index, got length = \", length(i))\n",
    "    }\n",
    "\n",
    "    # Now safe to slice\n",
    "    x <- self$X[i, , , drop = FALSE]$squeeze(1)  # [13, 45]\n",
    "    y <- self$y[i]                                \n",
    "\n",
    "    list(x = x, y = y)\n",
    "  },\n",
    "  .length = function() {\n",
    "    self$X$size(1)\n",
    "  }\n",
    ")\n",
    "\n",
    "\n",
    "train_ds <- Bre_Dataset(X, y)\n",
    "train_dl <- dataloader(\n",
    "  train_ds,\n",
    "  batch_size = BATCH_SIZE,\n",
    "  shuffle = TRUE,\n",
    "  num_workers = 0,    # set >0 if the env supports it\n",
    "  pin_memory = FALSE  # TRUE can help on CUDA with host->device copies\n",
    ")\n",
    "\n",
    "cat(\"Dataset created with\", length(train_ds), \"samples\\n\")\n",
    "cat(\"Batches per epoch:\", length(train_dl), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c1a5c9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "TempCNN <- nn_module(\n",
    "  \"TempCNN\",\n",
    "  initialize = function(input_channels = 13, n_classes = 9, dropout = 0.182039) {\n",
    "    self$conv_bn_relu1 <- nn_sequential(\n",
    "      nn_conv1d(input_channels, 128, kernel_size = 7, padding = 3),\n",
    "      nn_batch_norm1d(128),\n",
    "      nn_relu(),\n",
    "      nn_dropout(p = dropout)\n",
    "    )\n",
    "    self$conv_bn_relu2 <- nn_sequential(\n",
    "      nn_conv1d(128, 128, kernel_size = 7, padding = 3),\n",
    "      nn_batch_norm1d(128),\n",
    "      nn_relu(),\n",
    "      nn_dropout(p = dropout)\n",
    "    )\n",
    "    self$conv_bn_relu3 <- nn_sequential(\n",
    "      nn_conv1d(128, 128, kernel_size = 7, padding = 3),\n",
    "      nn_batch_norm1d(128),\n",
    "      nn_relu(),\n",
    "      nn_dropout(p = dropout)\n",
    "    )\n",
    "    self$flatten <- nn_flatten(start_dim = 2)\n",
    "    self$dense <- nn_sequential(\n",
    "      nn_linear(128 * 45, 512),\n",
    "      nn_batch_norm1d(512),\n",
    "      nn_relu(),\n",
    "      nn_dropout(p = dropout)\n",
    "    )\n",
    "    self$classifier <- nn_linear(512, n_classes)\n",
    "  },\n",
    "  forward = function(x) {\n",
    "    x <- self$conv_bn_relu1(x)\n",
    "    x <- self$conv_bn_relu2(x)\n",
    "    x <- self$conv_bn_relu3(x)\n",
    "    x <- self$flatten(x)\n",
    "    x <- self$dense(x)\n",
    "    self$classifier(x)  # logits\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfc9fe7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "safe_kappa <- function(y_true, y_pred) {\n",
    "  k <- tryCatch({\n",
    "    psych::cohen.kappa(cbind(as.integer(y_true), as.integer(y_pred)))$kappa\n",
    "  }, error = function(e) NA_real_)\n",
    "  ifelse(is.na(k), 0, k)\n",
    "}\n",
    "\n",
    "calculate_precision_recall_f1 <- function(y_true, y_pred, n_classes, average = \"macro\") {\n",
    "  y_true <- factor(y_true, levels = 1:n_classes)\n",
    "  y_pred <- factor(y_pred, levels = 1:n_classes)\n",
    "  if (average == \"micro\") {\n",
    "    tp <- sum(y_true == y_pred); total <- length(y_true)\n",
    "    precision <- recall <- f1 <- tp / total\n",
    "  } else {\n",
    "    precision_per_class <- numeric(n_classes)\n",
    "    recall_per_class    <- numeric(n_classes)\n",
    "    f1_per_class        <- numeric(n_classes)\n",
    "    for (i in 1:n_classes) {\n",
    "      tp <- sum(y_true == i & y_pred == i)\n",
    "      fp <- sum(y_true != i & y_pred == i)\n",
    "      fn <- sum(y_true == i & y_pred != i)\n",
    "      precision_per_class[i] <- ifelse(tp + fp == 0, 0, tp / (tp + fp))\n",
    "      recall_per_class[i]    <- ifelse(tp + fn == 0, 0, tp / (tp + fn))\n",
    "      denom <- precision_per_class[i] + recall_per_class[i]\n",
    "      f1_per_class[i]        <- ifelse(denom == 0, 0, 2 * precision_per_class[i] * recall_per_class[i] / denom)\n",
    "    }\n",
    "    if (average == \"macro\") {\n",
    "      precision <- mean(precision_per_class)\n",
    "      recall    <- mean(recall_per_class)\n",
    "      f1        <- mean(f1_per_class)\n",
    "    } else { # weighted\n",
    "      support <- as.numeric(table(y_true))\n",
    "      total_support <- sum(support)\n",
    "      precision <- sum(precision_per_class * support) / total_support\n",
    "      recall    <- sum(recall_per_class    * support) / total_support\n",
    "      f1        <- sum(f1_per_class        * support) / total_support\n",
    "    }\n",
    "  }\n",
    "  list(precision = precision, recall = recall, f1 = f1)\n",
    "}\n",
    "\n",
    "calculate_comprehensive_metrics <- function(y_true, y_pred, n_classes, epoch_time, iters_per_sec) {\n",
    "  micro <- calculate_precision_recall_f1(y_true, y_pred, n_classes, \"micro\")\n",
    "  macro <- calculate_precision_recall_f1(y_true, y_pred, n_classes, \"macro\")\n",
    "  weighted <- calculate_precision_recall_f1(y_true, y_pred, n_classes, \"weighted\")\n",
    "  list(\n",
    "    accuracy = mean(y_true == y_pred),\n",
    "    kappa = safe_kappa(y_true, y_pred),\n",
    "    f1_micro = micro$f1,\n",
    "    f1_macro = macro$f1,\n",
    "    f1_weighted = weighted$f1,\n",
    "    recall_micro = micro$recall,\n",
    "    recall_macro = macro$recall,\n",
    "    recall_weighted = weighted$recall,\n",
    "    precision_micro = micro$precision,\n",
    "    precision_macro = macro$precision,\n",
    "    precision_weighted = weighted$precision,\n",
    "    iters_per_sec = iters_per_sec,\n",
    "    epoch_time_sec = epoch_time\n",
    "  )\n",
    "}\n",
    "\n",
    "create_per_class_report <- function(y_true, y_pred, n_classes, class_names = NULL) {\n",
    "  if (is.null(class_names)) class_names <- paste0(\"Class_\", 1:n_classes)\n",
    "  y_true <- factor(y_true, levels = 1:n_classes)\n",
    "  y_pred <- factor(y_pred, levels = 1:n_classes)\n",
    "  report <- data.frame(\n",
    "    class     = class_names,\n",
    "    precision = numeric(n_classes),\n",
    "    recall    = numeric(n_classes),\n",
    "    f1_score  = numeric(n_classes),\n",
    "    support   = numeric(n_classes)\n",
    "  )\n",
    "  for (i in 1:n_classes) {\n",
    "    tp <- sum(y_true == i & y_pred == i)\n",
    "    fp <- sum(y_true != i & y_pred == i)\n",
    "    fn <- sum(y_true == i & y_pred != i)\n",
    "    report$precision[i] <- ifelse(tp + fp == 0, 0, tp / (tp + fp))\n",
    "    report$recall[i]    <- ifelse(tp + fn == 0, 0, tp / (tp + fn))\n",
    "    denom <- report$precision[i] + report$recall[i]\n",
    "    report$f1_score[i]  <- ifelse(denom == 0, 0, 2 * report$precision[i] * report$recall[i] / denom)\n",
    "    report$support[i]   <- sum(y_true == i)\n",
    "  }\n",
    "  report\n",
    "}\n",
    "\n",
    "# ---------- per-epoch files ----------\n",
    "epoch_file <- function(epoch, stem) sprintf(\"%s_epoch_%02d.csv\", stem, epoch)\n",
    "save_confusion <- function(y_true, y_pred, class_names, path) {\n",
    "  cm <- table(\n",
    "    Truth     = factor(y_true, levels = 1:length(class_names), labels = class_names),\n",
    "    Predicted = factor(y_pred, levels = 1:length(class_names), labels = class_names)\n",
    "  )\n",
    "  write.csv(as.data.frame.matrix(cm), path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e13d99a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss=0.7398, Acc=0.6926, F1_macro=0.4466, Kappa=0.6009, 3.82 it/s, Time=124.5s\n",
      "\n",
      "[Epoch 2] Loss=0.5433, Acc=0.7632, F1_macro=0.5230, Kappa=0.6932, 3.86 it/s, Time=123.1s\n",
      "\n",
      "[Epoch 3] Loss=0.5065, Acc=0.7771, F1_macro=0.5372, Kappa=0.7114, 3.87 it/s, Time=122.8s\n",
      "\n",
      "[Epoch 4] Loss=0.4890, Acc=0.7841, F1_macro=0.5443, Kappa=0.7205, 3.87 it/s, Time=122.6s\n",
      "\n",
      "[Epoch 5] Loss=0.4750, Acc=0.7902, F1_macro=0.5499, Kappa=0.7285, 3.85 it/s, Time=123.3s\n",
      "\n",
      "[Epoch 6] Loss=0.4646, Acc=0.7948, F1_macro=0.5538, Kappa=0.7346, 3.87 it/s, Time=122.7s\n",
      "\n",
      "[Epoch 7] Loss=0.4559, Acc=0.7981, F1_macro=0.5571, Kappa=0.7390, 3.87 it/s, Time=122.9s\n",
      "\n",
      "[Epoch 8] Loss=0.4479, Acc=0.8012, F1_macro=0.5609, Kappa=0.7430, 3.86 it/s, Time=123.0s\n",
      "\n",
      "[Epoch 9] Loss=0.4412, Acc=0.8043, F1_macro=0.5639, Kappa=0.7471, 3.88 it/s, Time=122.3s\n",
      "\n",
      "[Epoch 10] Loss=0.4352, Acc=0.8068, F1_macro=0.5680, Kappa=0.7504, 3.94 it/s, Time=120.5s\n",
      "\n",
      "[Epoch 11] Loss=0.4289, Acc=0.8095, F1_macro=0.5721, Kappa=0.7539, 3.97 it/s, Time=119.6s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 1389.78 seconds\n"
     ]
    }
   ],
   "source": [
    "R_training <- function() {\n",
    "  cat(\"Starting comprehensive training...\\n\")\n",
    "  model <- TempCNN(input_channels = 13, n_classes = N_CLASSES, dropout = DROPOUT_RATE)\n",
    "  if (cuda_is_available()) model <- model$to(device = torch_device(\"cuda\"))\n",
    "  criterion <- nn_cross_entropy_loss()\n",
    "  optimizer <- optim_adamw(model$parameters, lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "\n",
    "  training_log <- data.frame()\n",
    "  start_time <- Sys.time()\n",
    "\n",
    "  for (epoch in 1:EPOCHS) {\n",
    "    epoch_start_time <- Sys.time()\n",
    "    model$train()\n",
    "    epoch_losses <- c()\n",
    "    all_preds <- c()\n",
    "    all_true  <- c()\n",
    "    batch_count <- 0\n",
    "\n",
    "    coro::loop(for (batch in train_dl) {\n",
    "      batch_count <- batch_count + 1\n",
    "\n",
    "      # Move PER BATCH\n",
    "      x <- batch$x\n",
    "      t <- batch$y\n",
    "\n",
    "      # Ensure target dtype is long\n",
    "      t <- t$to(dtype = torch_long())\n",
    "\n",
    "      if (cuda_is_available()) {\n",
    "        x <- x$to(device = torch_device(\"cuda\"), non_blocking = TRUE)\n",
    "        t <- t$to(device = torch_device(\"cuda\"), non_blocking = TRUE)\n",
    "      }\n",
    "\n",
    "      # Forward\n",
    "      outputs <- model(x)\n",
    "      loss <- criterion(outputs, t)\n",
    "\n",
    "      # Backward\n",
    "      optimizer$zero_grad()\n",
    "      loss$backward()\n",
    "      optimizer$step()\n",
    "\n",
    "      # Collect metrics on CPU\n",
    "      epoch_losses <- c(epoch_losses, as.numeric(loss$detach()$cpu()))\n",
    "      preds <- torch_argmax(outputs$detach(), dim = 2)$cpu()\n",
    "      all_preds <- c(all_preds, as.integer(preds))\n",
    "      all_true  <- c(all_true,  as.integer(t$detach()$cpu()))\n",
    "    })\n",
    "\n",
    "    epoch_end_time <- Sys.time()\n",
    "    epoch_duration <- as.numeric(difftime(epoch_end_time, epoch_start_time, units = \"secs\"))\n",
    "    iters_per_sec <- batch_count / epoch_duration\n",
    "\n",
    "    # Epoch-level metrics\n",
    "    metrics <- calculate_comprehensive_metrics(all_true, all_preds, N_CLASSES, epoch_duration, iters_per_sec)\n",
    "    metrics$epoch <- epoch\n",
    "    metrics$loss  <- mean(epoch_losses)\n",
    "\n",
    "    metrics <- metrics[c(\n",
    "  \"epoch\",\n",
    "  \"loss\",\n",
    "  \"accuracy\",\n",
    "  \"kappa\",\n",
    "  \"f1_micro\",\n",
    "  \"f1_macro\",\n",
    "  \"f1_weighted\",\n",
    "  \"recall_micro\",\n",
    "  \"recall_macro\",\n",
    "  \"recall_weighted\",\n",
    "  \"precision_micro\",\n",
    "  \"precision_macro\",\n",
    "  \"precision_weighted\",\n",
    "  \"iters_per_sec\",\n",
    "  \"epoch_time_sec\"\n",
    ")]\n",
    "\n",
    "    # Per-class + confusion per epoch\n",
    "    per_class_epoch <- create_per_class_report(all_true, all_preds, N_CLASSES, class_names)\n",
    "    write.csv(per_class_epoch,\n",
    "              file.path(RESULTS_DIR, epoch_file(epoch, \"per_class\")),\n",
    "              row.names = FALSE)\n",
    "\n",
    "    save_confusion(all_true, all_preds, class_names,\n",
    "                   file.path(RESULTS_DIR, epoch_file(epoch, \"confusion_matrix\")))\n",
    "\n",
    "    # Log \n",
    "    message(sprintf(\n",
    "  \"[Epoch %d] Loss=%.4f, Acc=%.4f, F1_macro=%.4f, Kappa=%.4f, %.2f it/s, Time=%.1fs\",\n",
    "  epoch, metrics$loss, metrics$accuracy, metrics$f1_macro,\n",
    "  metrics$kappa, metrics$iters_per_sec, metrics$epoch_time_sec\n",
    "))\n",
    "\n",
    "    training_log <- rbind(training_log, as.data.frame(metrics))\n",
    "    write.csv(training_log,\n",
    "              file.path(RESULTS_DIR, paste0(MODEL_NAME, \"_log.csv\")),\n",
    "              row.names = FALSE)\n",
    "  }\n",
    "\n",
    "  total_time <- as.numeric(difftime(Sys.time(), start_time, units = \"secs\"))\n",
    "  cat(\"Total training time:\", round(total_time, 2), \"seconds\\n\")\n",
    "  list(model = model, history = training_log, training_time = total_time)\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Run training\n",
    "# ----------------------------\n",
    "training_results <- R_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085db365",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"Saving model...\\n\")\n",
    "torch_save(training_results$model, file.path(RESULTS_DIR, \"tempcnn_model.pt\"))\n",
    "if (!is.null(training_results$history)) {\n",
    "  write.csv(training_results$history, file.path(RESULTS_DIR, \"training_history.csv\"), row.names = FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f2cc76-e10d-4a5f-9d67-8753950da56f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing final evaluation...\n",
      "\n",
      "=== COMPREHENSIVE FINAL RESULTS ===\n",
      "Accuracy: 0.8148 \n",
      "Cohen's Kappa: 0.7596 \n",
      "F1 Macro: 0.5735 \n",
      "F1 Micro: 0.8148  (accuracy for the overall samples not per class)\n",
      "F1 Weighted: 0.8046 \n",
      "Precision Macro: 0.6718 \n",
      "Recall Macro: 0.5651 \n",
      "\n",
      "Training completed! Files saved to: training_logs_r \n",
      "\n",
      "Generated files:\n",
      "-  TempCNN _log.csv (per-epoch comprehensive metrics)\n",
      "- per_class_epoch_XX.csv (per-epoch per-class metrics)\n",
      "- confusion_matrix_epoch_XX.csv (per-epoch confusion matrices)\n",
      "- final_per_class_report.csv\n",
      "- final_confusion_matrix.csv\n",
      "- final_comprehensive_metrics.csv\n",
      "- tempcnn_model.pt\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Final evaluation on full train set\n",
    "# ----------------------------\n",
    "cat(\"Performing final evaluation...\\n\")\n",
    "training_results$model$eval()\n",
    "all_preds <- c(); all_true <- c()\n",
    "\n",
    "with_no_grad({\n",
    "  coro::loop(for (batch in train_dl) {\n",
    "    x <- batch$x\n",
    "    t <- batch$y$to(dtype = torch_long())\n",
    "    if (cuda_is_available()) {\n",
    "      x <- x$to(device = torch_device(\"cuda\"), non_blocking = TRUE)\n",
    "    }\n",
    "    out <- training_results$model(x)\n",
    "    preds_batch <- torch_argmax(out, dim = 2)$cpu()\n",
    "    all_preds <- c(all_preds, as.integer(preds_batch))\n",
    "    all_true  <- c(all_true,  as.integer(t$cpu()))\n",
    "  })\n",
    "})\n",
    "\n",
    "final_metrics <- calculate_comprehensive_metrics(all_true, all_preds, N_CLASSES, 0, 0)\n",
    "final_metrics$samples <- length(all_true)\n",
    "final_metrics$training_time <- training_results$training_time\n",
    "\n",
    "write.csv(as.data.frame(final_metrics), file.path(RESULTS_DIR, \"final_comprehensive_metrics.csv\"), row.names = FALSE)\n",
    "\n",
    "final_per_class <- create_per_class_report(all_true, all_preds, N_CLASSES, class_names)\n",
    "write.csv(final_per_class, file.path(RESULTS_DIR, \"final_per_class_report.csv\"), row.names = FALSE)\n",
    "\n",
    "final_conf_matrix_path <- file.path(RESULTS_DIR, \"final_confusion_matrix.csv\")\n",
    "save_confusion(all_true, all_preds, class_names, final_conf_matrix_path)\n",
    "\n",
    "cat(\"\\n=== COMPREHENSIVE FINAL RESULTS ===\\n\")\n",
    "cat(\"Accuracy:\", round(final_metrics$accuracy, 4), \"\\n\")\n",
    "cat(\"Cohen's Kappa:\", round(final_metrics$kappa, 4), \"\\n\")\n",
    "cat(\"F1 Macro:\", round(final_metrics$f1_macro, 4), \"\\n\")\n",
    "cat(\"F1 Micro:\", round(final_metrics$f1_micro, 4), \" (accuracy for the overall samples not per class)\\n\")\n",
    "cat(\"F1 Weighted:\", round(final_metrics$f1_weighted, 4), \"\\n\")\n",
    "cat(\"Precision Macro:\", round(final_metrics$precision_macro, 4), \"\\n\")\n",
    "cat(\"Recall Macro:\", round(final_metrics$recall_macro, 4), \"\\n\")\n",
    "cat(\"\\nTraining completed! Files saved to:\", RESULTS_DIR, \"\\n\")\n",
    "cat(\"\\nGenerated files:\\n\")\n",
    "cat(\"- \", MODEL_NAME, \"_log.csv (per-epoch comprehensive metrics)\\n\")\n",
    "cat(\"- per_class_epoch_XX.csv (per-epoch per-class metrics)\\n\")\n",
    "cat(\"- confusion_matrix_epoch_XX.csv (per-epoch confusion matrices)\\n\")\n",
    "cat(\"- final_per_class_report.csv\\n\")\n",
    "cat(\"- final_confusion_matrix.csv\\n\")\n",
    "cat(\"- final_comprehensive_metrics.csv\\n\")\n",
    "cat(\"- tempcnn_model.pt\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700f8e8",
   "metadata": {},
   "source": [
    "Run the trained model on the FRH04 Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94127c-1207-458e-85b2-b4742a2a74f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(torch)\n",
    "\n",
    "# Load the model\n",
    "# Path of the trained model\n",
    "tempcnn_model <- torch_load(\"/training_logs_r/tempcnn_model.pt\")\n",
    "tempcnn_model$eval()\n",
    "\n",
    "# FRH04 Tensor data \n",
    "X <- torch_load(\"/X_combined_4.pt\")   \n",
    "y_true <- torch_load(\"/y_combined_4.pt\") \n",
    "# Crop class names mapping\n",
    "classnames <- read.csv(\"/classmapping.csv\") %>% dplyr::rename(CODE_CULTU = code, class_id = id) %>% dplyr::group_by(class_id) %>% dplyr::summarise(ClassName = first(classname)) %>% dplyr::arrange(class_id) %>% dplyr::pull(ClassName)\n",
    "\n",
    "# Forward pass\n",
    "with_no_grad({\n",
    "  logits <- tempcnn_model(X$to(device = torch_device(\"cpu\")))\n",
    "})\n",
    "\n",
    "# Get predicted labels (argmax along class dimension)\n",
    "y_pred <- torch_max(logits, dim = 2)[[2]]$to(dtype = torch_int()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae5ac7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "classification_report_full <- function(y_true, y_pred, classnames = NULL) { # Ensure integer vectors (should be 0-based labels: 0...8) \n",
    "  y_true <- as.integer(y_true) \n",
    "  y_pred <- as.integer(y_pred)\n",
    "  classes <- sort(unique(c(y_true, y_pred))) \n",
    "  n_classes <- length(classes)\n",
    "  label_to_index <- setNames(seq_along(classes), classes) \n",
    "  y_true_idx <- label_to_index[as.character(y_true)] \n",
    "  y_pred_idx <- label_to_index[as.character(y_pred)]\n",
    "  cm <- matrix(0, nrow = n_classes, ncol = n_classes) \n",
    "  for (i in seq_along(y_true_idx)) \n",
    "  { cm[y_true_idx[i], y_pred_idx[i]] <- cm[y_true_idx[i], y_pred_idx[i]] + 1 }\n",
    "  # Per-class metrics \n",
    "  metrics <- tibble( ClassID = classes, \n",
    "                     Precision = numeric(n_classes), \n",
    "                     Recall = numeric(n_classes), \n",
    "                     F1 = numeric(n_classes), Support = numeric(n_classes) )\n",
    "  for (i in 1:n_classes) { \n",
    "    tp <- cm[i, i] \n",
    "    fp <- sum(cm[, i]) - tp \n",
    "    fn <- sum(cm[i, ]) - tp \n",
    "    support <- sum(cm[i, ])\n",
    "    precision <- if ((tp + fp) == 0) 0 else tp / (tp + fp) \n",
    "    recall <- if ((tp + fn) == 0) 0 else tp / (tp + fn) \n",
    "    f1 <- if ((precision + recall) == 0) 0 else 2 * precision * recall / (precision + recall) \n",
    "    metrics$Precision[i] <- precision \n",
    "    metrics$Recall[i] <- recall \n",
    "    metrics$F1[i] <- f1 \n",
    "    metrics$Support[i] <- support }\n",
    "  \n",
    "  # Add classnames \n",
    " if (!is.null(classnames)) {\n",
    "   classnames <- unique(classnames) \n",
    "   if (length(classnames) == n_classes) { \n",
    "     metrics <- metrics %>% mutate(ClassName = classnames[ClassID]) %>% select(ClassID, ClassName, everything()) \n",
    "     } \n",
    "   else { warning(\"Number of provided classnames does not match number of unique classes.\") } }\n",
    "\n",
    "  # === Overall metrics ===\n",
    "  total_correct <- sum(diag(cm))\n",
    "  total_samples <- sum(cm)\n",
    "  accuracy <- total_correct / total_samples\n",
    "  \n",
    "  macro_avg <- c(\n",
    "    Precision = mean(metrics$Precision),\n",
    "    Recall    = mean(metrics$Recall),\n",
    "    F1        = mean(metrics$F1)\n",
    "  )\n",
    "  \n",
    "  weighted_avg <- c(\n",
    "    Precision = sum(metrics$Precision * metrics$Support) / sum(metrics$Support),\n",
    "    Recall    = sum(metrics$Recall * metrics$Support) / sum(metrics$Support),\n",
    "    F1        = sum(metrics$F1 * metrics$Support) / sum(metrics$Support)\n",
    "  )\n",
    "  \n",
    "  return(list(\n",
    "    per_class = metrics,\n",
    "    accuracy = accuracy,\n",
    "    macro_avg = macro_avg,\n",
    "    weighted_avg = weighted_avg\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dd366",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(readr)\n",
    "report_r <- classification_report_full(y_true, y_pred, classnames)\n",
    "\n",
    "# Per-class results with class names\n",
    "print(report_r$per_class)\n",
    "write.csv(report_r$per_class, \"/r_classification_report.csv\", row.names = FALSE)\n",
    "\n",
    "# Overall\n",
    "cat(\"\\nOverall Accuracy:\", round(report_r$accuracy * 100, 2), \"%\\n\")\n",
    "cat(\"Macro Avg:\", round(report_r$macro_avg, 3), \"\\n\")\n",
    "cat(\"Weighted Avg:\", round(report_r$weighted_avg, 3), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b2834-f33c-4743-82e0-0e634c35d553",
   "metadata": {},
   "source": [
    "Prediction Results of FRH04 saved to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1205d-dcb6-433c-b510-5274f3eb94c7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(torch)\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "\n",
    "# Load model\n",
    "tempcnn_model <- torch_load(\"/training_logs_r/tempcnn_model.pt\")\n",
    "tempcnn_model$eval()\n",
    "\n",
    "# Load tensors\n",
    "X       <- torch_load(\"/torchdata/X_combined_4.pt\")         \n",
    "y_true  <- torch_load(\"/torchdata/y_combined_4.pt\")         \n",
    "field_ids <- torch_load(\"/field_ids_combined_4.pt\") \n",
    "\n",
    "# Class names (ensure index corresponds to your 1-based labels)\n",
    "classnames <- read.csv(\"/classmapping.csv\") %>%\n",
    "  dplyr::rename(CODE_CULTU = code, class_id = id) %>%\n",
    "  dplyr::group_by(class_id) %>%\n",
    "  dplyr::summarise(ClassName = dplyr::first(classname), .groups = \"drop\") %>%\n",
    "  dplyr::arrange(class_id) %>%\n",
    "  dplyr::pull(ClassName)\n",
    "\n",
    "# Forward pass (CPU here; switch to CUDA if available)\n",
    "with_no_grad({\n",
    "  logits <- tempcnn_model(X$to(device = torch_device(\"cpu\")))  \n",
    "})\n",
    "\n",
    "probs <- nnf_softmax(logits, dim = 2)\n",
    "mx <- torch_max(probs, dim = 2)\n",
    "top1_prob <- as.numeric(mx[[1]]$cpu())\n",
    "y_pred    <- as.integer(mx[[2]]$cpu())\n",
    "\n",
    "\n",
    "\n",
    "# results table\n",
    "y_true_r <- as.integer(y_true$to(device = \"cpu\")$to(dtype = torch_int())$contiguous()$numpy())\n",
    "y_pred_r <- as.integer(y_pred$to(device = \"cpu\")$numpy())\n",
    "fid_r    <- as.integer(field_ids$to(device = \"cpu\")$numpy())\n",
    "p1_r     <- as.numeric(top1_prob$to(device = \"cpu\")$numpy())\n",
    "\n",
    "df_pred <- tibble::tibble(\n",
    "  field_id   = fid_r,\n",
    "  y_true_id  = y_true_r,\n",
    "  y_true_cls = classnames[y_true_r],\n",
    "  y_pred_id  = y_pred_r,\n",
    "  y_pred_cls = classnames[y_pred_r],\n",
    "  top1_prob  = round(p1_r, 6),\n",
    "  correct    = (y_true_r == y_pred_r)\n",
    ")\n",
    "\n",
    "\n",
    "output_csv <- \"/predictions_frh04_with_field_ids.csv\"\n",
    "readr::write_csv(df_pred, output_csv)\n",
    "cat(\"Saved:\", out_csv, \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
