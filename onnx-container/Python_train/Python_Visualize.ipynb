{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1835155b",
   "metadata": {},
   "source": [
    "Visualise the Results for Python\n",
    "Native and ONNX logits comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import breizhcrops\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm \n",
    "from breizhcrops import BreizhCrops\n",
    "from breizhcrops.models import TempCNN\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "DATA_PATH = \"/breizh_data\" \n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEVEL = \"L1C\"\n",
    "PRELOAD_RAM = False\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "tempcnn = breizhcrops.models.TempCNN()\n",
    "model = tempcnn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "frh04 = BreizhCrops(region=\"frh04\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "model.load_state_dict(torch.load(\"log_tempcnn/tempcnn_py_model.pt\",map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(frh04, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 1\n",
    "sess_options.inter_op_num_threads = 1\n",
    "ort.set_default_logger_severity(2)  \n",
    "providers = (\n",
    "    [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "    if \"CUDAExecutionProvider\" in ort.get_available_providers()\n",
    "    else [\"CPUExecutionProvider\"]\n",
    ")\n",
    "onnx_model = \"log_tempcnn/tempcnn_py_model.onnx\"\n",
    "session = ort.InferenceSession(onnx_model, providers=providers, sess_options=sess_options)\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "all_native_logits = []\n",
    "all_onnx_logits = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    x = batch[0].to(device)\n",
    "\n",
    "    # Native\n",
    "    with torch.no_grad():\n",
    "        y_native = model(x).cpu().numpy()\n",
    "\n",
    "    # ONNX\n",
    "    x_np = x.cpu().numpy().astype(np.float32)\n",
    "    y_onnx = session.run(None, {input_name: x_np})[0]\n",
    "\n",
    "    all_native_logits.append(y_native)\n",
    "    all_onnx_logits.append(y_onnx)\n",
    "\n",
    "native_logits = np.concatenate(all_native_logits, axis=0)\n",
    "onnx_logits   = np.concatenate(all_onnx_logits, axis=0)\n",
    "\n",
    "np.save(\"native_logits_python.npy\", native_logits)\n",
    "np.save(\"onnx_logits_python.npy\", onnx_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f751ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735252d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660161d3",
   "metadata": {},
   "source": [
    "Computed MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ebc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(native_logits - onnx_logits))\n",
    "max_err = np.max(np.abs(native_logits - onnx_logits))\n",
    "top1_agree = np.mean(np.argmax(native_logits,1) == np.argmax(onnx_logits,1))\n",
    "print(f\"MAE={mae:.2e}, Max|err|={max_err:.2e}, Top1 agreement={top1_agree*100:.4f}%\")\n",
    "\n",
    "rmse = np.sqrt(np.mean((native_logits - onnx_logits)**2))\n",
    "from numpy.linalg import norm\n",
    "cos = np.median([np.dot(a,b)/(norm(a)*norm(b) + 1e-12) for a,b in zip(native_logits, onnx_logits)])\n",
    "print(f\"RMSE={rmse:.2e}, median cosine={cos:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8feb1a",
   "metadata": {},
   "source": [
    "Prediction Maps for FRH04 and Belle-Ile Region subset of FRH04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "import os\n",
    "DATA_PATH = \"/breizh_data\"\n",
    "LEVEL = \"L1C\"\n",
    "PRELOAD_RAM = False\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "C = 9  # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pytorch_model():\n",
    "    \"\"\"Load and setup PyTorch model\"\"\"\n",
    "    frh04 = BreizhCrops(region=\"frh04\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "    # Load PyTorch model\n",
    "    tempcnn = breizhcrops.models.TempCNN()\n",
    "    model = tempcnn\n",
    "    state = torch.load(\"/log_tempcnn/tempcnn_py_model.pt\",map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    model.to(DEVICE).eval()\n",
    "    return model, frh04\n",
    "\n",
    "def setup_onnx_model():\n",
    "    \"\"\"Load and setup ONNX model\"\"\"\n",
    "    sess_options = ort.SessionOptions()\n",
    "    sess_options.intra_op_num_threads = 1\n",
    "    sess_options.inter_op_num_threads = 1\n",
    "    ort.set_default_logger_severity(2)\n",
    "    \n",
    "    providers = (\n",
    "        [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "        if \"CUDAExecutionProvider\" in ort.get_available_providers()\n",
    "        else [\"CPUExecutionProvider\"]\n",
    "    )\n",
    "    \n",
    "    session = ort.InferenceSession(\n",
    "        \"/log_tempcnn/tempcnn_py_model.onnx\",\n",
    "        sess_options=sess_options,\n",
    "        providers=providers\n",
    "    )\n",
    "    \n",
    "    return session\n",
    "\n",
    "def compare_single_sample(pytorch_model, onnx_session, x, y_true, field_id, sample_idx, verbose=False):\n",
    "    \"\"\"Compare PyTorch and ONNX predictions on a single sample\"\"\"\n",
    "    \n",
    "    input_name = onnx_session.get_inputs()[0].name\n",
    "    output_name = onnx_session.get_outputs()[0].name\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    x_tensor = x.unsqueeze(0).to(DEVICE)  \n",
    "    x_numpy = x.unsqueeze(0).numpy().astype(np.float32) \n",
    "    \n",
    "    # PyTorch inference\n",
    "    with torch.no_grad():\n",
    "        logits_pt = pytorch_model(x_tensor)  \n",
    "        probs_pt = softmax(logits_pt)  \n",
    "        pred_pt = probs_pt.argmax(dim=1).item()\n",
    "        conf_pt = probs_pt.max(dim=1).values.item()\n",
    "        probs_pt_np = probs_pt.cpu().numpy()[0]  \n",
    "    \n",
    "    # ONNX inference\n",
    "    log_probs_onnx = onnx_session.run([output_name], {input_name: x_numpy})[0][0]  \n",
    "    probs_onnx = np.exp(log_probs_onnx)  \n",
    "    pred_onnx = int(np.argmax(probs_onnx))\n",
    "    conf_onnx = float(np.max(probs_onnx))\n",
    "    \n",
    "    # Calculate differences\n",
    "    prob_diff = np.abs(probs_pt_np - probs_onnx)\n",
    "    max_prob_diff = np.max(prob_diff)\n",
    "    \n",
    "    results = {\n",
    "        'sample_idx': sample_idx,\n",
    "        'field_id': field_id,\n",
    "        'ground_truth': y_true,\n",
    "        'pytorch_pred': pred_pt,\n",
    "        'onnx_pred': pred_onnx,\n",
    "        'pytorch_conf': conf_pt,\n",
    "        'onnx_conf': conf_onnx,\n",
    "        'predictions_match': pred_pt == pred_onnx,\n",
    "        'pytorch_correct': pred_pt == y_true,\n",
    "        'onnx_correct': pred_onnx == y_true,\n",
    "        'max_prob_diff': max_prob_diff,\n",
    "        'probs_pytorch': probs_pt_np.copy(),\n",
    "        'probs_onnx': probs_onnx.copy(),\n",
    "        'prob_differences': prob_diff\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nSample {sample_idx} (Field {field_id}):\")\n",
    "        print(f\"  Ground Truth: {y_true}\")\n",
    "        print(f\"  PyTorch:  Pred={pred_pt}, Conf={conf_pt:.4f}, Correct={pred_pt==y_true}\")\n",
    "        print(f\"  ONNX:     Pred={pred_onnx}, Conf={conf_onnx:.4f}, Correct={pred_onnx==y_true}\")\n",
    "        print(f\"  Match: {pred_pt == pred_onnx}, Max Prob Diff: {max_prob_diff:.6f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_disagreement_patterns(disagreements, frh04):\n",
    "    \"\"\"Analyze patterns in disagreements between models\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DISAGREEMENT PATTERN ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_disagreements = len(disagreements)\n",
    "    print(f\"Total disagreements: {total_disagreements}\")\n",
    "    \n",
    "    # Ground truth class distribution of disagreements\n",
    "    gt_classes = [d['ground_truth'] for d in disagreements]\n",
    "    gt_counts = np.bincount(gt_classes, minlength=C)\n",
    "    \n",
    "    print(f\"\\nDisagreements by Ground Truth Class:\")\n",
    "    for class_idx in range(C):\n",
    "        class_name = frh04.classname[class_idx]\n",
    "        count = gt_counts[class_idx]\n",
    "        percentage = count / total_disagreements * 100 if total_disagreements > 0 else 0\n",
    "        print(f\"  {class_idx:>2} ({class_name:<20}): {count:>4} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Most common disagreement patterns\n",
    "    disagreement_patterns = defaultdict(int)\n",
    "    for d in disagreements:\n",
    "        pattern = f\"{d['pytorch_pred']} → {d['onnx_pred']}\"\n",
    "        disagreement_patterns[pattern] += 1\n",
    "    \n",
    "    print(f\"\\nMost Common Disagreement Patterns:\")\n",
    "    sorted_patterns = sorted(disagreement_patterns.items(), key=lambda x: x[1], reverse=True)\n",
    "    for pattern, count in sorted_patterns[:10]:\n",
    "        percentage = count / total_disagreements * 100\n",
    "        pt_class, onnx_class = pattern.split(' → ')\n",
    "        pt_name = frh04.classname[int(pt_class)][:15]\n",
    "        onnx_name = frh04.classname[int(onnx_class)][:15]\n",
    "        print(f\"  {pt_name:<15} → {onnx_name:<15}: {count:>4} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Probability difference analysis\n",
    "    prob_diffs = [d['max_prob_diff'] for d in disagreements]\n",
    "    print(f\"\\nProbability Difference Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(prob_diffs):.6f}\")\n",
    "    print(f\"  Std:  {np.std(prob_diffs):.6f}\")\n",
    "    print(f\"  Min:  {np.min(prob_diffs):.6f}\")\n",
    "    print(f\"  Max:  {np.max(prob_diffs):.6f}\")\n",
    "    \n",
    "    # Cases where both are wrong vs one is right\n",
    "    both_wrong = sum(1 for d in disagreements if not d['pytorch_correct'] and not d['onnx_correct'])\n",
    "    pt_right = sum(1 for d in disagreements if d['pytorch_correct'] and not d['onnx_correct'])\n",
    "    onnx_right = sum(1 for d in disagreements if not d['pytorch_correct'] and d['onnx_correct'])\n",
    "    \n",
    "    print(f\"\\nCorrectness in Disagreements:\")\n",
    "    print(f\"  Both wrong:     {both_wrong:>4} ({both_wrong/total_disagreements*100:5.1f}%)\")\n",
    "    print(f\"  PyTorch right:  {pt_right:>4} ({pt_right/total_disagreements*100:5.1f}%)\")\n",
    "    print(f\"  ONNX right:     {onnx_right:>4} ({onnx_right/total_disagreements*100:5.1f}%)\")\n",
    "\n",
    "def save_detailed_comparison(all_results, save_path=\"detailed_comparison.csv\"):\n",
    "    \"\"\"Save detailed comparison results to CSV\"\"\"\n",
    "    \n",
    "    df_data = []\n",
    "    for result in all_results:\n",
    "        row = {\n",
    "            'sample_idx': result['sample_idx'],\n",
    "            'field_id': result['field_id'],\n",
    "            'ground_truth': result['ground_truth'],\n",
    "            'pytorch_pred': result['pytorch_pred'],\n",
    "            'onnx_pred': result['onnx_pred'],\n",
    "            'pytorch_conf': result['pytorch_conf'],\n",
    "            'onnx_conf': result['onnx_conf'],\n",
    "            'predictions_match': result['predictions_match'],\n",
    "            'pytorch_correct': result['pytorch_correct'],\n",
    "            'onnx_correct': result['onnx_correct'],\n",
    "            'max_prob_diff': result['max_prob_diff']\n",
    "        }\n",
    "        \n",
    "        # Add individual class probabilities\n",
    "        for class_idx in range(C):\n",
    "            row[f'prob_pytorch_class_{class_idx}'] = result['probs_pytorch'][class_idx]\n",
    "            row[f'prob_onnx_class_{class_idx}'] = result['probs_onnx'][class_idx]\n",
    "            row[f'prob_diff_class_{class_idx}'] = result['prob_differences'][class_idx]\n",
    "        \n",
    "        df_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"\\nDetailed results saved to: {save_path}\")\n",
    "    return df\n",
    "    \n",
    "def run_comprehensive_comparison(num_samples=None, save_results=True, verbose_samples=0):\n",
    "    \"\"\"Run comprehensive comparison between PyTorch and ONNX models\"\"\"\n",
    "    \n",
    "    print(\"Setting up models...\")\n",
    "    pytorch_model, frh04 = setup_pytorch_model()\n",
    "    onnx_session = setup_onnx_model()\n",
    "    print(f\"Dataset size: {len(frh04)} samples\")\n",
    "    total_samples = len(frh04) if num_samples is None else min(num_samples, len(frh04))\n",
    "    print(f\"Processing {total_samples} samples...\")\n",
    "    all_results = []\n",
    "    disagreements = []\n",
    "    for i in range(total_samples):\n",
    "        x, y_true, field_id = frh04[i]\n",
    "        \n",
    "        # Compare models on this sample\n",
    "        result = compare_single_sample(\n",
    "            pytorch_model, onnx_session, x, y_true, field_id, i, \n",
    "            verbose=(i < verbose_samples) )\n",
    "        \n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Track disagreements\n",
    "        if not result['predictions_match']:\n",
    "            disagreements.append(result)\n",
    "        # Progress update\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            current_agreement = (total_samples - len(disagreements)) / (i + 1)\n",
    "            print(f\"  Processed {i+1}/{total_samples} samples. Current agreement: {current_agreement:.3f}\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    pytorch_preds = [r['pytorch_pred'] for r in all_results]\n",
    "    onnx_preds = [r['onnx_pred'] for r in all_results]\n",
    "    ground_truth = [r['ground_truth'] for r in all_results]\n",
    "    field_ids = [r['field_id'] for r in all_results]\n",
    "    \n",
    "    pytorch_accuracy = accuracy_score(ground_truth, pytorch_preds)\n",
    "    onnx_accuracy = accuracy_score(ground_truth, onnx_preds)\n",
    "    agreement = np.mean([r['predictions_match'] for r in all_results])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL COMPARISON RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Samples processed: {total_samples:,}\")\n",
    "    print(f\"PyTorch accuracy: {pytorch_accuracy:.6f}\")\n",
    "    print(f\"ONNX accuracy:    {onnx_accuracy:.6f}\")\n",
    "    print(f\"Model agreement:  {agreement:.6f} ({agreement*100:.2f}%)\")\n",
    "    print(f\"Disagreements:    {len(disagreements):,}\")\n",
    "    \n",
    "    # Analyze disagreement patterns\n",
    "    if disagreements:\n",
    "        analyze_disagreement_patterns(disagreements, frh04)\n",
    "    \n",
    "    # Save detailed results\n",
    "    if save_results:\n",
    "        os.makedirs(\"maps\", exist_ok=True)\n",
    "        df = save_detailed_comparison(all_results, \"maps/detailed_pytorch_onnx_comparison.csv\")\n",
    "        # Save disagreements \n",
    "        if disagreements:\n",
    "            disagreement_df = df[~df['predictions_match']]\n",
    "            disagreement_df.to_csv(\"maps/disagreements_only.csv\", index=False)\n",
    "            print(f\"Disagreements saved to: maps/disagreements_only.csv\")\n",
    "        \n",
    "        # Save summary \n",
    "        save_summary_stats(all_results, frh04, field_ids, \"maps/summary_stats.txt\")\n",
    "        \n",
    "        # Create field mapping\n",
    "        create_field_mapping(field_ids, all_results, frh04, \"maps/field_id_mapping.csv\")\n",
    "    \n",
    "    return all_results, disagreements, field_ids\n",
    "\n",
    "def save_summary_stats(all_results, frh04, field_ids, save_path=\"summary_stats.txt\"):\n",
    "    \"\"\"Save summary statistics to a text file\"\"\"\n",
    "    \n",
    "    pytorch_preds = [r['pytorch_pred'] for r in all_results]\n",
    "    onnx_preds = [r['onnx_pred'] for r in all_results]\n",
    "    ground_truth = [r['ground_truth'] for r in all_results]\n",
    "    \n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"PYTORCH vs ONNX MODEL COMPARISON SUMMARY\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total samples processed: {len(all_results):,}\\n\")\n",
    "        f.write(f\"PyTorch accuracy: {accuracy_score(ground_truth, pytorch_preds):.6f}\\n\")\n",
    "        f.write(f\"ONNX accuracy: {accuracy_score(ground_truth, onnx_preds):.6f}\\n\")\n",
    "        f.write(f\"Model agreement: {np.mean([r['predictions_match'] for r in all_results]):.6f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"CLASS DISTRIBUTION:\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        gt_counts = np.bincount(ground_truth, minlength=C)\n",
    "        for class_idx in range(C):\n",
    "            class_name = frh04.classname[class_idx]\n",
    "            count = gt_counts[class_idx]\n",
    "            percentage = count / len(all_results) * 100\n",
    "            f.write(f\"{class_idx:>2} ({class_name:<25}): {count:>6,} ({percentage:5.1f}%)\\n\")\n",
    "        \n",
    "        f.write(\"\\nCONFIDENCE STATISTICS:\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        pytorch_confs = [r['pytorch_conf'] for r in all_results]\n",
    "        onnx_confs = [r['onnx_conf'] for r in all_results]\n",
    "        f.write(f\"PyTorch confidence - Mean: {np.mean(pytorch_confs):.4f}, Std: {np.std(pytorch_confs):.4f}\\n\")\n",
    "        f.write(f\"ONNX confidence - Mean: {np.mean(onnx_confs):.4f}, Std: {np.std(onnx_confs):.4f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nFile generated on: {pd.Timestamp.now()}\\n\")\n",
    "    \n",
    "    print(f\"Summary statistics saved to: {save_path}\")\n",
    "\n",
    "def create_field_mapping(field_ids, all_results, frh04, save_path=\"maps/field_id_mapping.csv\"):\n",
    "    \"\"\"Create a simple field ID to prediction mapping\"\"\"\n",
    "    \n",
    "    mapping_data = []\n",
    "    for i, field_id in enumerate(field_ids):\n",
    "        result = all_results[i]\n",
    "        mapping_data.append({\n",
    "            'field_id': field_id,\n",
    "            'ground_truth_class_id': result['ground_truth'],\n",
    "            'ground_truth_class_name': frh04.classname[result['ground_truth']],\n",
    "            'predicted_class_id': result['pytorch_pred'],  \n",
    "            'onnx_class_id': result['onnx_pred'],\n",
    "            'predicted_class_name': frh04.classname[result['pytorch_pred']],\n",
    "            'onnx_class_name': frh04.classname[result['onnx_pred']],\n",
    "            'confidence': result['pytorch_conf'],\n",
    "            'onnx_confidence': result['onnx_conf']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(mapping_data)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Field mapping saved to: {save_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, disagreements, field_ids = run_comprehensive_comparison(\n",
    "        num_samples=None,  \n",
    "        save_results=True,\n",
    "        #verbose_samples=5\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAnalysis complete!\")\n",
    "    print(f\"Files saved:\")\n",
    "    print(f\"   - maps/detailed_pytorch_onnx_comparison.csv\")\n",
    "    print(f\"   - maps/summary_stats.txt\")\n",
    "    print(f\"   - maps/field_id_mapping.csv\")\n",
    "    \n",
    "    if disagreements:\n",
    "        print(f\" - maps/disagreements_only.csv (disagreement cases only)\")\n",
    "    else:\n",
    "        print(f\"Perfect agreement - no disagreements to analyze!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1389fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "belle_ile = BreizhCrops(region=\"belle-ile\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "frh04 = BreizhCrops(region=\"frh04\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "field_parcels_geodataframe = belle_ile.geodataframe() #frh04 or belle_ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pyproj import CRS\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf265ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR     = \"maps\"   \n",
    "DETAIL_CSV   = \"detailed_pytorch_onnx_comparison.csv\"  # prediction file \n",
    "PRED_SOURCE  = \"pytorch\"   # choose: \"onnx\" or \"pytorch\"\n",
    "FIXED_SCALE_KM = None  \n",
    "TITLE_REGION = \"FRH04\"  # title text\n",
    "\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def clean_tensor_int(x):\n",
    "    \"\"\"Convert 'tensor(8)' -> 8, '8'->8, 8->8.\"\"\"\n",
    "    if isinstance(x, str) and x.startswith(\"tensor(\") and x.endswith(\")\"):\n",
    "        x = x[7:-1]\n",
    "    return int(float(x))\n",
    "\n",
    "def _safe_series(x):\n",
    "    \"\"\"Flatten to 1-D Series to avoid MultiIndex issues with isna()/value_counts().\"\"\"\n",
    "    return pd.Series(np.asarray(x, dtype=object))\n",
    "\n",
    "def add_north_arrow(ax, xy=(0.95, 0.92), length=0.10):\n",
    "    \"\"\"\n",
    "    Draw a north arrow.\n",
    "    \"\"\"\n",
    "    ax.annotate(\n",
    "        '', xy=xy, xytext=(xy[0], xy[1]-length),\n",
    "        xycoords='axes fraction', textcoords='axes fraction',\n",
    "        arrowprops=dict(arrowstyle='-|>', lw=1.8, color='k')\n",
    "    )\n",
    "    ax.text(xy[0], xy[1]+0.02, 'N', transform=ax.transAxes,\n",
    "            ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "\n",
    "def _nice_number_m(x_m):\n",
    "    \"\"\"Round meters to a nice 1-2-5*10^n value.\"\"\"\n",
    "    if x_m <= 0:\n",
    "        return 1.0\n",
    "    exp = int(np.floor(np.log10(x_m)))\n",
    "    frac = x_m / (10 ** exp)\n",
    "    if frac < 1.5:\n",
    "        nice = 1\n",
    "    elif frac < 3:\n",
    "        nice = 2\n",
    "    elif frac < 7:\n",
    "        nice = 5\n",
    "    else:\n",
    "        nice = 10\n",
    "    return nice * (10 ** exp)\n",
    "\n",
    "def _meters_per_deg_lon_at_lat(lat_deg):\n",
    "    return 111320.0 * math.cos(math.radians(lat_deg))\n",
    "\n",
    "\n",
    "def fmt_pct(x):\n",
    "    return f\"{x:.1f}%\"\n",
    "\n",
    "\n",
    "def add_qgis_scalebar_auto(ax, gdf_plotted, total_km=None, segments=4,\n",
    "                           loc='lower right', pad_frac=0.05, edge_lw=0.8, textsize=10):\n",
    "    from pyproj import CRS\n",
    "    import math\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Rectangle\n",
    "\n",
    "    def _nice_number_m(x_m):\n",
    "        if x_m <= 0: return 1.0\n",
    "        exp = int(np.floor(np.log10(x_m)))\n",
    "        frac = x_m / (10 ** exp)\n",
    "        nice = 1 if frac < 1.5 else (2 if frac < 3 else (5 if frac < 7 else 10))\n",
    "        return nice * (10 ** exp)\n",
    "\n",
    "    def _meters_per_deg_lon_at_lat(lat_deg):\n",
    "        return 111320.0 * math.cos(math.radians(lat_deg))\n",
    "\n",
    "    if gdf_plotted.crs is None:\n",
    "        raise ValueError(\"GeoDataFrame has no CRS. Set a CRS or reproject before drawing scalebar.\")\n",
    "\n",
    " \n",
    "    minx, maxx = ax.get_xlim()\n",
    "    miny, maxy = ax.get_ylim()\n",
    "    width  = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    crs = CRS.from_user_input(gdf_plotted.crs)\n",
    "\n",
    "    if crs.is_projected:\n",
    "        width_m_est = width\n",
    "        meters_total = (total_km * 1000.0) if total_km is not None else _nice_number_m(width_m_est / 5.0)\n",
    "        bar_len_native = meters_total\n",
    "        seg_native     = bar_len_native / float(segments)\n",
    "        bar_thick      = 0.014 * height\n",
    "        label_mid_km   = meters_total / 2000.0\n",
    "    else:\n",
    "        mid_lat = 0.5 * (miny + maxy)\n",
    "        m_per_deg_lon = max(_meters_per_deg_lon_at_lat(mid_lat), 1e-6)\n",
    "        width_m_est   = width * m_per_deg_lon\n",
    "        meters_total  = (total_km * 1000.0) if total_km is not None else _nice_number_m(width_m_est / 5.0)\n",
    "        bar_len_deg   = meters_total / m_per_deg_lon\n",
    "        seg_native    = bar_len_deg / float(segments)\n",
    "        bar_len_native = bar_len_deg\n",
    "        bar_thick     = 0.014 * height\n",
    "        label_mid_km  = meters_total / 2000.0\n",
    "\n",
    "    # Anchor position\n",
    "    if loc == 'lower right':\n",
    "        x0 = maxx - pad_frac*width - bar_len_native\n",
    "        y0 = miny + pad_frac*height\n",
    "        label_above = True\n",
    "    elif loc == 'lower left':\n",
    "        x0 = minx + pad_frac*width\n",
    "        y0 = miny + pad_frac*height\n",
    "        label_above = True\n",
    "    elif loc == 'upper right':\n",
    "        x0 = maxx - pad_frac*width - bar_len_native\n",
    "        y0 = maxy - pad_frac*height - 2.5*bar_thick\n",
    "        label_above = False\n",
    "    else:  # 'upper left'\n",
    "        x0 = minx + pad_frac*width\n",
    "        y0 = maxy - pad_frac*height - 2.5*bar_thick\n",
    "        label_above = False\n",
    "    for i in range(segments):\n",
    "        xi = x0 + i*seg_native\n",
    "        ax.add_patch(Rectangle((xi, y0), seg_native, bar_thick,\n",
    "                               facecolor=('k' if i % 2 == 0 else 'white'),\n",
    "                               edgecolor='k', lw=edge_lw))\n",
    "\n",
    "    # Ticks\n",
    "    tick_y0 = y0\n",
    "    tick_y1 = y0 + bar_thick\n",
    "    ax.plot([x0, x0], [tick_y0, tick_y1], color='k', lw=edge_lw)\n",
    "    ax.plot([x0 + bar_len_native/2, x0 + bar_len_native/2], [tick_y0, tick_y1], color='k', lw=edge_lw)\n",
    "    ax.plot([x0 + bar_len_native, x0 + bar_len_native], [tick_y0, tick_y1], color='k', lw=edge_lw)\n",
    "\n",
    "    # Labels\n",
    "    ty = (y0 + 1.9*bar_thick) if label_above else (y0 - 0.9*bar_thick)\n",
    "    va = 'bottom' if label_above else 'top'\n",
    "\n",
    "    ax.text(x0, ty, \"0\", ha='center', va=va, fontsize=textsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "    ax.text(x0 + bar_len_native/2, ty, f\"{label_mid_km:g}\", ha='center', va=va, fontsize=textsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "\n",
    "    end_label = f\"{(meters_total/1000.0):g} km\" if meters_total >= 1000 else f\"{int(round(meters_total))} m\"\n",
    "    ax.text(x0 + bar_len_native, ty, end_label, ha='center', va=va, fontsize=textsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "\n",
    "def make_maps(field_parcels_geodataframe,\n",
    "              detail_csv=DETAIL_CSV,\n",
    "              pred_source=PRED_SOURCE,\n",
    "              save_dir=SAVE_DIR,\n",
    "              fixed_scale_km=FIXED_SCALE_KM,\n",
    "              title_region=TITLE_REGION):\n",
    "    # ---------- prediction CSV -------------\n",
    "    pred_df = pd.read_csv(detail_csv)\n",
    "    # clean essential columns\n",
    "    pred_df[\"field_id\"]     = pred_df[\"field_id\"].astype(int)\n",
    "    pred_df[\"ground_truth\"] = pred_df[\"ground_truth\"].apply(clean_tensor_int)\n",
    "    pred_df[\"pytorch_pred\"] = pred_df[\"pytorch_pred\"].astype(int)\n",
    "    pred_df[\"onnx_pred\"]    = pred_df[\"onnx_pred\"].astype(int)\n",
    "\n",
    "    # choose prediction source\n",
    "    if pred_source.lower() == \"onnx\":\n",
    "        pred_idx_col = \"onnx_pred\"\n",
    "        title_suffix = \"ONNX\"\n",
    "    elif pred_source.lower() == \"pytorch\":\n",
    "        pred_idx_col = \"pytorch_pred\"\n",
    "        title_suffix = \"PyTorch\"\n",
    "    else:\n",
    "        raise ValueError(\"PRED_SOURCE must be 'onnx' or 'pytorch'.\")\n",
    "\n",
    "    # slim frame for merge\n",
    "    pred_merge = pred_df.loc[:, [\"field_id\", \"ground_truth\", pred_idx_col]].rename(\n",
    "        columns={\"field_id\": \"id\", pred_idx_col: \"pred_idx\"}\n",
    "    )\n",
    "\n",
    "    # ---------- merge with GeoDataFrame ----------\n",
    "    gdf = field_parcels_geodataframe.copy()\n",
    "    gdf = gdf.merge(pred_merge, on=\"id\", how=\"left\")\n",
    "    gdf_ll = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    idx_to_name = {}\n",
    "    for idx, sub in gdf_ll.dropna(subset=[\"ground_truth\"]).groupby(\"ground_truth\"):\n",
    "        if \"classname\" in sub and not sub[\"classname\"].isna().all():\n",
    "            name = sub[\"classname\"].mode(dropna=True)\n",
    "            idx_to_name[int(idx)] = str(name.iloc[0]) if len(name) else f\"class_{int(idx)}\"\n",
    "\n",
    "\n",
    "    all_idxs = set(gdf_ll[\"ground_truth\"].dropna().astype(int)) \\\n",
    "               .union(set(gdf_ll[\"pred_idx\"].dropna().astype(int)))\n",
    "    for k in all_idxs:\n",
    "        idx_to_name.setdefault(int(k), f\"class_{int(k)}\")\n",
    "\n",
    "    # Map names\n",
    "    gdf_ll[\"gt_class_name\"]   = gdf_ll[\"ground_truth\"].map(lambda v: idx_to_name.get(int(v), f\"class_{int(v)}\") if pd.notna(v) else None)\n",
    "    gdf_ll[\"pred_class_name\"] = gdf_ll[\"pred_idx\"].map(lambda v: idx_to_name.get(int(v), f\"class_{int(v)}\") if pd.notna(v) else None)\n",
    "\n",
    "    if \"classname\" in gdf_ll.columns and not gdf_ll[\"classname\"].isna().all():\n",
    "        gdf_ll[\"gt_class_name\"] = gdf_ll[\"classname\"].astype(str)\n",
    "    classes = sorted(\n",
    "        pd.unique(\n",
    "            pd.concat([\n",
    "                _safe_series(gdf_ll[\"gt_class_name\"]),\n",
    "                _safe_series(gdf_ll[\"pred_class_name\"])\n",
    "            ], ignore_index=True).dropna().astype(str)\n",
    "        )\n",
    "    )\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", len(classes))\n",
    "    class2color = {cls: cmap(i) for i, cls in enumerate(classes)}\n",
    "\n",
    "    # Keep categoricals aligned with classes\n",
    "    gdf_ll[\"gt_class_name\"]   = pd.Categorical(_safe_series(gdf_ll[\"gt_class_name\"]).astype(str),   categories=classes, ordered=True)\n",
    "    gdf_ll[\"pred_class_name\"] = pd.Categorical(_safe_series(gdf_ll[\"pred_class_name\"]).astype(str), categories=classes, ordered=True)\n",
    "\n",
    "    # Colors\n",
    "    gdf_ll[\"gt_color\"]   = _safe_series(gdf_ll[\"gt_class_name\"]).map(class2color)\n",
    "    gdf_ll[\"pred_color\"] = _safe_series(gdf_ll[\"pred_class_name\"]).map(class2color)\n",
    "\n",
    "    gdf_m = gdf_ll.to_crs(epsg=3857)\n",
    "    for col in [\"gt_color\", \"pred_color\"]:\n",
    "        gdf_m[col] = gdf_ll[col]\n",
    "    _scale_km = fixed_scale_km \n",
    "\n",
    "    # =========================\n",
    "    # 1) Ground-truth map\n",
    "    # =========================\n",
    "    gt_counts = (_safe_series(gdf_ll[\"gt_class_name\"]).value_counts(dropna=True)\n",
    "                 .reindex(classes, fill_value=0))\n",
    "    gt_total  = int(gt_counts.sum())\n",
    "    gt_pct    = gt_counts / max(gt_total, 1) * 100.0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    gdf_m.plot(color=gdf_m[\"gt_color\"], linewidth=0.05, edgecolor=\"none\", ax=ax)\n",
    "    print(gdf_m.total_bounds) \n",
    "    print(\"Width in km:\", (gdf_m.total_bounds[2] - gdf_m.total_bounds[0]) / 1000)\n",
    "    ax.set_title(f\"{title_region} — Ground Truth (BreizhCrops)\", pad=12)\n",
    "    ax.set_xlabel(\"\"); ax.set_ylabel(\"\")\n",
    "    add_north_arrow(ax, xy=(0.95, 0.92), length=0.10)\n",
    "    ax.set_aspect('equal')\n",
    "    add_qgis_scalebar_auto(ax, gdf_m, total_km=_scale_km, segments=4, loc='lower right')\n",
    "\n",
    "    handles_gt = []\n",
    "    for cls in classes:\n",
    "        cnt = int(gt_counts.loc[cls])\n",
    "        pct = float(gt_pct.loc[cls])\n",
    "        handles_gt.append(\n",
    "            mpatches.Patch(facecolor=class2color[cls], edgecolor=\"none\",\n",
    "                           label=f\"{cls} — {fmt_pct(pct)} ({cnt:,})\")\n",
    "        )\n",
    "    ax.legend(handles=handles_gt, loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "              frameon=True, title=\"Class\")\n",
    "    fig.tight_layout(); fig.subplots_adjust(right=0.82)\n",
    "    fig.savefig(os.path.join(save_dir, \"gr.png\"), dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "\n",
    "    # ==================================\n",
    "    # 2) Predicted map (PyTorch or ONNX)\n",
    "    # ==================================\n",
    "    pred_counts = (_safe_series(gdf_ll[\"pred_class_name\"]).value_counts(dropna=True)\n",
    "                   .reindex(classes, fill_value=0))\n",
    "    pred_total  = int(pred_counts.sum())\n",
    "    pred_pct    = pred_counts / max(pred_total, 1) * 100.0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    gdf_m.plot(color=gdf_m[\"pred_color\"], linewidth=0.05, edgecolor=\"none\", ax=ax)\n",
    "    print(gdf_m.total_bounds)  \n",
    "    print(\"Width in km:\", (gdf_m.total_bounds[2] - gdf_m.total_bounds[0]) / 1000)\n",
    "    ax.set_title(f\"{title_region} — Predicted — ({title_suffix})\", pad=12)\n",
    "    ax.set_xlabel(\"\"); ax.set_ylabel(\"\")\n",
    "    add_north_arrow(ax, xy=(0.95, 0.92), length=0.10)\n",
    "    ax.set_aspect('equal')\n",
    "    add_qgis_scalebar_auto(ax, gdf_m, total_km=_scale_km, segments=4, loc='lower right')\n",
    "\n",
    "    handles_pr = []\n",
    "    for cls in classes:\n",
    "        cnt = int(pred_counts.loc[cls])\n",
    "        pct = float(pred_pct.loc[cls])\n",
    "        handles_pr.append(\n",
    "            mpatches.Patch(facecolor=class2color[cls], edgecolor=\"none\",\n",
    "                           label=f\"{cls} — {fmt_pct(pct)} ({cnt:,})\")\n",
    "        )\n",
    "    ax.legend(handles=handles_pr, loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "              frameon=True, title=\"Predicted Class\")\n",
    "    fig.tight_layout(); fig.subplots_adjust(right=0.82)\n",
    "    \n",
    "    fig.savefig(os.path.join(save_dir, \"pr.png\"), dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ==========================================\n",
    "    # 3) Correct vs Incorrect\n",
    "    # ==========================================\n",
    "    gdf_ll[\"correct\"] = (_safe_series(gdf_ll[\"gt_class_name\"]) == _safe_series(gdf_ll[\"pred_class_name\"]))\n",
    "    palette_ci = {True: \"#1a9850\", False: \"#d73027\"}\n",
    "    gdf_ll[\"ci_color\"] = gdf_ll[\"correct\"].map(palette_ci)\n",
    "\n",
    "    gdf_m = gdf_ll.to_crs(epsg=3857)\n",
    "    gdf_m[\"ci_color\"] = gdf_ll[\"ci_color\"]\n",
    "    print(gdf_m.total_bounds) \n",
    "    print(\"Width in km:\", (gdf_m.total_bounds[2] - gdf_m.total_bounds[0]) / 1000)\n",
    "\n",
    "    s_pred     = _safe_series(gdf_ll[\"pred_class_name\"])\n",
    "    n_total    = int(s_pred.notna().sum())\n",
    "    n_correct  = int(_safe_series(gdf_ll[\"correct\"]).sum())\n",
    "    n_incorrect = n_total - n_correct\n",
    "    p_correct   = 100.0 * n_correct / max(n_total, 1)\n",
    "    p_incorrect = 100.0 * n_incorrect / max(n_total, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    gdf_m.plot(color=gdf_m[\"ci_color\"], linewidth=0.05, edgecolor=\"none\", ax=ax)\n",
    "    ax.set_title(f\"{title_region} — Correct vs Incorrect — ({title_suffix})\", pad=12)\n",
    "    ax.set_xlabel(\"\"); ax.set_ylabel(\"\")\n",
    "    add_north_arrow(ax, xy=(0.95, 0.92), length=0.10)\n",
    "    ax.set_aspect('equal')\n",
    "    add_qgis_scalebar_auto(ax, gdf_m, total_km=_scale_km, segments=4, loc='lower right')\n",
    "\n",
    "    handles_ci = [\n",
    "        mpatches.Patch(color=palette_ci[True],  label=f\"Correct — {p_correct:.1f}% ({n_correct:,})\"),\n",
    "        mpatches.Patch(color=palette_ci[False], label=f\"Incorrect — {p_incorrect:.1f}% ({n_incorrect:,})\"),\n",
    "    ]\n",
    "    ax.legend(handles=handles_ci, loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "              frameon=True, title=\"Prediction\")\n",
    "    fig.tight_layout(); fig.subplots_adjust(right=0.72)\n",
    "    fig.savefig(os.path.join(save_dir, \"co.png\"), dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"Saved:\",\n",
    "          os.path.join(save_dir, \"gr.png\"),\n",
    "          os.path.join(save_dir, \"pr_py.png\"),\n",
    "          os.path.join(save_dir, \"co.png\"))\n",
    "\n",
    "\n",
    "make_maps(\n",
    "    field_parcels_geodataframe,\n",
    "    detail_csv=DETAIL_CSV,\n",
    "    pred_source=\"pytorch\",     # pytorch or onnx \n",
    "    save_dir=\"maps\",\n",
    "    fixed_scale_km=None,       \n",
    "    title_region=\"FRH04\"    # appears in the figure title\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927ea40",
   "metadata": {},
   "source": [
    "#Belle-Ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f446435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "from pyproj import CRS\n",
    "import contextily as ctx\n",
    "DETAIL_CSV   = \"detailed_pytorch_onnx_comparison.csv\"  \n",
    "PRED_SOURCE  = \"onnx\"   # \"pytorch\" or \"onnx\"\n",
    "SAVE_DIR     = \"maps\"\n",
    "TITLE_REGION = \"Belle-ile\"\n",
    "FIXED_SCALE_KM = None \n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def clean_tensor_int(x):\n",
    "    if isinstance(x, str) and x.startswith(\"tensor(\") and x.endswith(\")\"):\n",
    "        x = x[7:-1]\n",
    "    return int(float(x))\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p <= 0:  return \"0%\"\n",
    "    if p < 0.1: return \"<0.1%\"\n",
    "    return f\"{p:.1f}%\"\n",
    "\n",
    "def add_north_arrow(ax, xy=(0.95, 0.92), length=0.10):\n",
    "    ax.annotate('', xy=xy, xytext=(xy[0], xy[1]-length),\n",
    "                xycoords='axes fraction', textcoords='axes fraction',\n",
    "                arrowprops=dict(arrowstyle='-|>', lw=1.8, color='w'))\n",
    "    ax.text(xy[0], xy[1]+0.02, 'N', transform=ax.transAxes,\n",
    "            ha='center', va='bottom', fontsize=12, weight='bold',color='w')\n",
    "\n",
    "def _nice_number_m(x_m):\n",
    "    if x_m <= 0: return 1.0\n",
    "    exp  = int(np.floor(np.log10(x_m)))\n",
    "    frac = x_m / (10**exp)\n",
    "    nice = 1 if frac < 1.5 else (2 if frac < 3 else (5 if frac < 7 else 10))\n",
    "    return nice * (10**exp)\n",
    "\n",
    "def _meters_per_deg_lon_at_lat(lat_deg):\n",
    "    return 111320.0 * math.cos(math.radians(lat_deg))\n",
    "\n",
    "def add_qgis_scalebar_auto(ax, gdf_plotted, total_km=None, segments=4,\n",
    "                           loc='lower left', pad_frac=0.05, edge_lw=0.8, textsize=10,\n",
    "                           bgcolor='lightgray', bg_alpha=0.6, pad_px=5):\n",
    "    \"\"\"\n",
    "    Scale bar with optional gray background box.\n",
    "    Uses CURRENT axes extent (what you see), honoring the plotted CRS.\n",
    "    \"\"\"\n",
    "    if gdf_plotted.crs is None:\n",
    "        raise ValueError(\"GeoDataFrame has no CRS. Set a CRS or reproject before drawing scalebar.\")\n",
    "    crs = CRS.from_user_input(gdf_plotted.crs)\n",
    "\n",
    "    minx, maxx = ax.get_xlim()\n",
    "    miny, maxy = ax.get_ylim()\n",
    "    width  = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    if crs.is_projected:\n",
    "        width_m_est = width\n",
    "        meters_total = (total_km*1000.0) if total_km is not None else _nice_number_m(width_m_est/5.0)\n",
    "        bar_len_native = meters_total\n",
    "        seg_native     = bar_len_native / float(segments)\n",
    "        bar_thick      = 0.014 * height\n",
    "        label_mid_km   = meters_total / 2000.0\n",
    "    else:\n",
    "        mid_lat = 0.5*(miny+maxy)\n",
    "        m_per_deg_lon = max(_meters_per_deg_lon_at_lat(mid_lat), 1e-6)\n",
    "        width_m_est   = width * m_per_deg_lon\n",
    "        meters_total  = (total_km*1000.0) if total_km is not None else _nice_number_m(width_m_est/5.0)\n",
    "        bar_len_deg   = meters_total / m_per_deg_lon\n",
    "        seg_native    = bar_len_deg / float(segments)\n",
    "        bar_len_native = bar_len_deg\n",
    "        bar_thick     = 0.014 * height\n",
    "        label_mid_km  = meters_total / 2000.0\n",
    "\n",
    "    # anchor\n",
    "    if loc == 'lower left':\n",
    "        x0 = minx + pad_frac*width\n",
    "        y0 = miny + pad_frac*height\n",
    "        label_above = True\n",
    "    elif loc == 'lower right':\n",
    "        x0 = maxx - pad_frac*width - bar_len_native\n",
    "        y0 = miny + pad_frac*height\n",
    "        label_above = True\n",
    "    elif loc == 'upper right':\n",
    "        x0 = maxx - pad_frac*width - bar_len_native\n",
    "        y0 = maxy - pad_frac*height - 2.5*bar_thick\n",
    "        label_above = False\n",
    "    else:  # upper left\n",
    "        x0 = minx + pad_frac*width\n",
    "        y0 = maxy - pad_frac*height - 2.5*bar_thick\n",
    "        label_above = False\n",
    "\n",
    "    # alternating blocks\n",
    "    for i in range(segments):\n",
    "        xi = x0 + i*seg_native\n",
    "        ax.add_patch(Rectangle((xi, y0), seg_native, bar_thick,\n",
    "                               facecolor=('grey' if i%2==0 else 'white'),\n",
    "                               edgecolor='grey', lw=edge_lw, zorder=2))\n",
    "\n",
    "    # ticks\n",
    "    ax.plot([x0, x0], [y0, y0+bar_thick], color='k', lw=edge_lw, zorder=3)\n",
    "    ax.plot([x0+bar_len_native/2, x0+bar_len_native/2], [y0, y0+bar_thick], color='k', lw=edge_lw, zorder=3)\n",
    "    ax.plot([x0+bar_len_native,   x0+bar_len_native],   [y0, y0+bar_thick], color='k', lw=edge_lw, zorder=3)\n",
    "\n",
    "    # labels\n",
    "    ty = (y0 + 1.9*bar_thick) if label_above else (y0 - 0.9*bar_thick)\n",
    "    va = 'bottom' if label_above else 'top'\n",
    "    ax.text(x0, ty, \"0\", ha='center', va=va, fontsize=textsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7), zorder=4)\n",
    "    ax.text(x0+bar_len_native/2, ty, f\"{label_mid_km:g}\", ha='center', va=va, fontsize=textsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7), zorder=4)\n",
    "    end_label = f\"{(meters_total/1000.0):g} km\" if meters_total>=1000 else f\"{int(round(meters_total))} m\"\n",
    "    ax.text(x0+bar_len_native, ty, end_label, ha='center', va=va, fontsize=textsize,\n",
    "            bbox=dict(facecolor='white', edgecolor='none', alpha=0.7), zorder=4)\n",
    "\n",
    "\n",
    "def add_bg(ax, crs, zoom=\"auto\", attribution=True, alpha=1.0):\n",
    "    \"\"\"Add a Contextily basemap behind data in EPSG:3857.\"\"\"\n",
    "    providers_try = [\n",
    "        \"Esri.WorldImagery\",\"CartoDB.Positron\", \"CartoDB.Voyager\", \"OpenStreetMap.Mapnik\",\n",
    "         \"Esri.WorldTopoMap\", \"OpenTopoMap\",\n",
    "    ]\n",
    "    def _resolve(path):\n",
    "        prov = ctx.providers\n",
    "        for part in path.split(\".\"):\n",
    "            prov = getattr(prov, part, None)\n",
    "            if prov is None:\n",
    "                return None\n",
    "        return prov\n",
    "    for name in providers_try:\n",
    "        prov = _resolve(name)\n",
    "        if prov is not None:\n",
    "            ctx.add_basemap(ax, crs=crs, source=prov, zoom=zoom, attribution=attribution, alpha=alpha)\n",
    "            return name\n",
    "    ctx.add_basemap(ax, crs=crs, zoom=zoom, attribution=attribution, alpha=alpha)\n",
    "    return \"default(OSM)\"\n",
    "\n",
    "\n",
    "gdf_source = field_parcels_geodataframe  \n",
    "gdf_3857 = gdf_source.to_crs(epsg=3857)\n",
    "\n",
    "# Build class palette + counts/% for legend\n",
    "classes = sorted(gdf_3857[\"classname\"].dropna().astype(str).unique())\n",
    "cmap = plt.cm.get_cmap(\"tab20\", len(classes))\n",
    "class2color = {cls: cmap(i) for i, cls in enumerate(classes)}\n",
    "gt_counts = gdf_3857[\"classname\"].astype(str).value_counts().reindex(classes, fill_value=0)\n",
    "gt_total  = int(gt_counts.sum())\n",
    "gt_pct    = (gt_counts / max(gt_total, 1)) * 100.0\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "gdf_3857.plot(\n",
    "    color=gdf_3857[\"classname\"].astype(str).map(class2color),\n",
    "    linewidth=0.05, edgecolor=\"none\", ax=ax, zorder=2\n",
    ")\n",
    "minx, miny, maxx, maxy = gdf_3857.total_bounds\n",
    "pad_x = 0.02 * (maxx - minx)\n",
    "pad_y = 0.02 * (maxy - miny)\n",
    "ax.set_xlim(minx - pad_x, maxx + pad_x)\n",
    "ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "\n",
    "# add basemap \n",
    "_ = add_bg(ax, gdf_3857.crs, zoom=\"auto\", attribution=True, alpha=1.0)\n",
    "gdf_3857.plot(\n",
    "    color=gdf_3857[\"classname\"].astype(str).map(class2color),\n",
    "    linewidth=0.05, edgecolor=\"none\", ax=ax, zorder=3\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 1) Ground-truth map\n",
    "# =========================\n",
    "\n",
    "ax.set_title(\"Belle-ile — Ground Truth (BreizhCrops)\", pad=12)\n",
    "ax.set_xlabel(\"\"); ax.set_ylabel(\"\"); ax.set_aspect(\"equal\")\n",
    "add_north_arrow(ax, xy=(0.95, 0.92), length=0.10)\n",
    "add_qgis_scalebar_auto(ax, gdf_3857, total_km=None, segments=4, loc='lower left')  \n",
    "handles_gt = []\n",
    "for cls in classes:\n",
    "    cnt = int(gt_counts.loc[cls])\n",
    "    pct = float(gt_pct.loc[cls])\n",
    "    handles_gt.append(mpatches.Patch(facecolor=class2color[cls], edgecolor=\"none\",\n",
    "                                     label=f\"{cls} — {fmt_pct(pct)} ({cnt:,})\"))\n",
    "ax.legend(handles=handles_gt, loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "          frameon=True, title=\"Class\")\n",
    "\n",
    "fig.tight_layout(); fig.subplots_adjust(right=0.82)\n",
    "fig.savefig(os.path.join(SAVE_DIR, \"gr_bille.png\"), dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# ==================================\n",
    "# 2) Predicted map (PyTorch or ONNX)\n",
    "# ==================================\n",
    "\n",
    "pred = pd.read_csv(DETAIL_CSV)\n",
    "pred[\"field_id\"]     = pred[\"field_id\"].astype(int)\n",
    "pred[\"ground_truth\"] = pred[\"ground_truth\"].apply(clean_tensor_int)\n",
    "pred[\"pytorch_pred\"] = pred[\"pytorch_pred\"].astype(int)\n",
    "pred[\"onnx_pred\"]    = pred[\"onnx_pred\"].astype(int)\n",
    "\n",
    "pred_idx_col = \"onnx_pred\" if PRED_SOURCE.lower() == \"onnx\" else \"pytorch_pred\"\n",
    "\n",
    "\n",
    "merge_df = pred.loc[:, [\"field_id\", \"ground_truth\", pred_idx_col]].rename(\n",
    "    columns={\"field_id\": \"id\", pred_idx_col: \"pred_idx\"}\n",
    ")\n",
    "gdf = field_parcels_geodataframe.merge(merge_df, on=\"id\", how=\"left\")\n",
    "idx_to_name = {}\n",
    "for idx, sub in gdf.dropna(subset=[\"ground_truth\", \"classname\"]).groupby(\"ground_truth\"):\n",
    "    mode = sub[\"classname\"].mode(dropna=True)\n",
    "    idx_to_name[int(idx)] = str(mode.iloc[0]) if len(mode) else f\"class_{int(idx)}\"\n",
    "\n",
    "all_idxs = set(gdf[\"ground_truth\"].dropna().astype(int)) | set(gdf[\"pred_idx\"].dropna().astype(int))\n",
    "for k in all_idxs:\n",
    "    idx_to_name.setdefault(int(k), f\"class_{int(k)}\")\n",
    "\n",
    "# Predicted class names\n",
    "gdf[\"pred_class_name\"] = gdf[\"pred_idx\"].map(lambda v: idx_to_name.get(int(v), f\"class_{int(v)}\") if pd.notna(v) else None)\n",
    "gdf_3857 = gdf.to_crs(epsg=3857)\n",
    "classes = sorted(pd.unique(pd.concat([\n",
    "    gdf_3857[\"classname\"].dropna().astype(str),\n",
    "    gdf_3857[\"pred_class_name\"].dropna().astype(str)\n",
    "])))\n",
    "gdf_3857[\"pred_class_name\"] = pd.Categorical(gdf_3857[\"pred_class_name\"], categories=classes, ordered=True)\n",
    "\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"tab20\", len(classes))\n",
    "class2color = {cls: cmap(i) for i, cls in enumerate(classes)}\n",
    "pred_counts = gdf_3857[\"pred_class_name\"].astype(str).value_counts().reindex(classes, fill_value=0)\n",
    "pred_total  = int(pred_counts.sum())\n",
    "pred_pct    = (pred_counts / max(pred_total, 1)) * 100.0\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "gdf_3857.plot(\n",
    "    color=gdf_3857[\"pred_class_name\"].astype(str).map(class2color),\n",
    "    linewidth=0.05, edgecolor=\"none\", ax=ax, zorder=2\n",
    ")\n",
    "minx, miny, maxx, maxy = gdf_3857.total_bounds\n",
    "pad_x = 0.02 * (maxx - minx)\n",
    "pad_y = 0.02 * (maxy - miny)\n",
    "ax.set_xlim(minx - pad_x, maxx + pad_x)\n",
    "ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "_ = add_bg(ax, gdf_3857.crs, zoom=\"auto\", attribution=True, alpha=1.0)\n",
    "gdf_3857.plot(\n",
    "    color=gdf_3857[\"pred_class_name\"].astype(str).map(class2color),\n",
    "    linewidth=0.05, edgecolor=\"none\", ax=ax, zorder=3\n",
    ")\n",
    "ax.set_title(f\"{TITLE_REGION} — Predicted (TempCNN, {PRED_SOURCE.upper()})\", pad=12)\n",
    "ax.set_xlabel(\"\"); ax.set_ylabel(\"\"); ax.set_aspect(\"equal\")\n",
    "add_north_arrow(ax, xy=(0.95, 0.92), length=0.10)\n",
    "add_qgis_scalebar_auto(ax, gdf_3857, total_km=FIXED_SCALE_KM, segments=4, loc='lower left')  \n",
    "handles_pr = []\n",
    "for cls in classes:\n",
    "    cnt = int(pred_counts.loc[cls])\n",
    "    pct = float(pred_pct.loc[cls])\n",
    "    handles_pr.append(\n",
    "        mpatches.Patch(facecolor=class2color[cls], edgecolor=\"none\",\n",
    "                       label=f\"{cls} — {fmt_pct(pct)} ({cnt:,})\")\n",
    "    )\n",
    "ax.legend(handles=handles_pr, loc=\"center left\", bbox_to_anchor=(1.02, 0.5),\n",
    "          frameon=True, title=\"Predicted Class\")\n",
    "\n",
    "plt.tight_layout(); plt.subplots_adjust(right=0.82)\n",
    "out_path = os.path.join(SAVE_DIR, f\"pred_{PRED_SOURCE.lower()}.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.show()\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# ==========================================\n",
    "# 3) Correct vs Incorrect\n",
    "# ==========================================\n",
    "gdf[\"correct\"] = (gdf[\"classname\"].astype(str) == gdf[\"pred_class_name\"].astype(str)) & gdf[\"pred_class_name\"].notna()\n",
    "palette = {True: \"#1a9850\", False: \"#d73027\"}\n",
    "gdf[\"color_ci\"] = gdf[\"correct\"].map(palette)\n",
    "gdf_3857 = gdf.to_crs(epsg=3857)\n",
    "n_total    = int(gdf_3857[\"pred_class_name\"].notna().sum())\n",
    "n_correct  = int(gdf_3857[\"correct\"].sum())\n",
    "n_incorrect = n_total - n_correct\n",
    "p_correct   = (100.0 * n_correct / max(n_total, 1))\n",
    "p_incorrect = (100.0 * n_incorrect / max(n_total, 1))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "gdf_3857.plot(color=gdf_3857[\"color_ci\"], linewidth=0.05, edgecolor=\"none\", ax=ax, zorder=2)\n",
    "minx, miny, maxx, maxy = gdf_3857.total_bounds\n",
    "pad_x = 0.02 * (maxx - minx)\n",
    "pad_y = 0.02 * (maxy - miny)\n",
    "ax.set_xlim(minx - pad_x, maxx + pad_x)\n",
    "ax.set_ylim(miny - pad_y, maxy + pad_y)\n",
    "_ = add_bg(ax, gdf_3857.crs, zoom=\"auto\", attribution=True, alpha=1.0)\n",
    "gdf_3857.plot(color=gdf_3857[\"color_ci\"], linewidth=0.05, edgecolor=\"none\", ax=ax, zorder=3)\n",
    "\n",
    "ax.set_title(\"Belle-ile — Correct vs Incorrect — Python\", pad=12)\n",
    "ax.set_xlabel(\"\"); ax.set_ylabel(\"\"); ax.set_aspect(\"equal\")\n",
    "add_north_arrow(ax, xy=(0.95, 0.92), length=0.10)\n",
    "add_qgis_scalebar_auto(ax, gdf_3857, total_km=None, segments=4, loc='lower left')  \n",
    "\n",
    "handles = [\n",
    "    mpatches.Patch(color=palette[True],  label=f\"Correct — {fmt_pct(p_correct)} ({n_correct:,})\"),\n",
    "    mpatches.Patch(color=palette[False], label=f\"Incorrect — {fmt_pct(p_incorrect)} ({n_incorrect:,})\"),\n",
    "]\n",
    "ax.legend(handles=handles, loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=True, title=\"Prediction\")\n",
    "\n",
    "plt.tight_layout(); plt.subplots_adjust(right=0.82)\n",
    "out_path = os.path.join(SAVE_DIR, \"correct_incorrect_python.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "plt.show()\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
