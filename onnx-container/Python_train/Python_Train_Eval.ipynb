{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e347cc94",
   "metadata": {},
   "source": [
    "Python Training using PyTorch framework TempCNN model on FRH01-FRH03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import breizhcrops\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "from breizhcrops import BreizhCrops\n",
    "from breizhcrops.models import TempCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration ----\n",
    "DATA_PATH = \"hdf5-files/breizh_data\"                  \n",
    "LEVEL = \"L1C\"\n",
    "PRELOAD_RAM = False\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 11\n",
    "LEARNING_RATE = 2.38e-4           \n",
    "WEIGHT_DECAY = 5.18e-5              \n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOGDIR = \"/to save the training logs/log_tempcnn\"\n",
    "MODEL_NAME = \"tempcnn_py_model\"\n",
    "\n",
    "\n",
    "# ---- Load Data ----\n",
    "print(\"Loading BreizhCrops datasets\")\n",
    "frh01 = BreizhCrops(region=\"frh01\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "frh02 = BreizhCrops(region=\"frh02\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "frh03 = BreizhCrops(region=\"frh03\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "\n",
    "train_dataset = ConcatDataset([frh01, frh02, frh03])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()  \n",
    ")\n",
    "\n",
    "\n",
    "num_classes = len(frh01.classes)\n",
    "ndims = 13 if LEVEL == \"L1C\" else 10\n",
    "sequencelength = 45\n",
    "class_names = frh01.classes\n",
    "print(f\"Total samples: {len(train_dataset)} | Batches/epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Initialize Model ----\n",
    "model = TempCNN(input_dim=ndims, num_classes=num_classes, sequencelength=sequencelength).to(DEVICE)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "os.makedirs(LOGDIR, exist_ok=True)\n",
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Training Loop ----\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    losses = []\n",
    "    y_true_all, y_pred_all = [], []\n",
    "\n",
    "    for x, y_true, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        x, y_true = x.to(DEVICE), y_true.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        y_true_all.append(y_true.cpu())\n",
    "        y_pred_all.append(y_pred.argmax(dim=1).cpu())\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    iters_per_sec = len(train_loader) / duration\n",
    "\n",
    "    y_true_all = torch.cat(y_true_all)\n",
    "    y_pred_all = torch.cat(y_pred_all)\n",
    "\n",
    " # ---- Metrics ----\n",
    "    metrics = {\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": sum(losses) / len(losses),\n",
    "        \"accuracy\": sklearn.metrics.accuracy_score(y_true_all, y_pred_all),\n",
    "        \"kappa\": sklearn.metrics.cohen_kappa_score(y_true_all, y_pred_all),\n",
    "        \"f1_micro\": sklearn.metrics.f1_score(y_true_all, y_pred_all, average=\"micro\"),\n",
    "        \"f1_macro\": sklearn.metrics.f1_score(y_true_all, y_pred_all, average=\"macro\"),\n",
    "        \"f1_weighted\": sklearn.metrics.f1_score(y_true_all, y_pred_all, average=\"weighted\"),\n",
    "        \"recall_micro\": sklearn.metrics.recall_score(y_true_all, y_pred_all, average=\"micro\"),\n",
    "        \"recall_macro\": sklearn.metrics.recall_score(y_true_all, y_pred_all, average=\"macro\"),\n",
    "        \"recall_weighted\": sklearn.metrics.recall_score(y_true_all, y_pred_all, average=\"weighted\"),\n",
    "        \"precision_micro\": sklearn.metrics.precision_score(y_true_all, y_pred_all, average=\"micro\"),\n",
    "        \"precision_macro\": sklearn.metrics.precision_score(y_true_all, y_pred_all, average=\"macro\"),\n",
    "        \"precision_weighted\": sklearn.metrics.precision_score(y_true_all, y_pred_all, average=\"weighted\"),\n",
    "        \"iters_per_sec\": iters_per_sec,\n",
    "        \"epoch_time_sec\": duration\n",
    "    }\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss={metrics['loss']:.4f}, Acc={metrics['accuracy']:.4f}, \"\n",
    "          f\"F1_macro={metrics['f1_macro']:.4f}, Kappa={metrics['kappa']:.4f}, \"\n",
    "          f\"{iters_per_sec:.2f} it/s, Time={duration:.1f}s\")\n",
    "\n",
    "    \n",
    "    # ---- Save overall metrics ----\n",
    "    log.append(metrics)\n",
    "    pd.DataFrame(log).to_csv(os.path.join(LOGDIR, f\"{MODEL_NAME}_log.csv\"), index=False)\n",
    "\n",
    "    # ---- Save per-class metrics ----\n",
    "    class_report = sklearn.metrics.classification_report(y_true_all, y_pred_all,\n",
    "                                                         target_names=class_names, output_dict=True)\n",
    "    df_class_report = pd.DataFrame(class_report).transpose()\n",
    "    df_class_report.to_csv(os.path.join(LOGDIR, f\"{MODEL_NAME}_epoch{epoch+1}_per_class.csv\"))\n",
    "\n",
    "    # ---- Confusion matrix ----\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true_all, y_pred_all)\n",
    "    pd.DataFrame(cm, index=class_names, columns=class_names).to_csv(\n",
    "        os.path.join(LOGDIR, f\"{MODEL_NAME}_epoch{epoch+1}_confusion.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9322741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Save final model ----\n",
    "torch.save(model.state_dict(), os.path.join(LOGDIR, f\"{MODEL_NAME}.pt\"))\n",
    "print(f\"Model saved to {LOGDIR}/{MODEL_NAME}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be5bcf",
   "metadata": {},
   "source": [
    "Exporting the trained model to ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Export to ONNX ----\n",
    "dummy_input = torch.randn(1, sequencelength, ndims).to(DEVICE)\n",
    "onnx_path = os.path.join(LOGDIR, f\"{MODEL_NAME}.onnx\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model, dummy_input, onnx_path,\n",
    "    input_names=['input'], output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
    "    export_params=True, opset_version=11\n",
    ")\n",
    "\n",
    "print(f\"Model exported to ONNX: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf80ccf",
   "metadata": {},
   "source": [
    "To validate the ONNX model using ONNX checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- ONNX checker ----\n",
    "import onnx\n",
    "from onnx import checker\n",
    "\n",
    "def is_onnx_model_valid(path):\n",
    "    try:\n",
    "        model = onnx.load(path)\n",
    "        checker.check_model(model)\n",
    "        print(\"ONNX model is valid!\")\n",
    "        return True\n",
    "    except onnx.checker.ValidationError as e:\n",
    "        print(\"ONNX model is not valid!\")\n",
    "        print(f\"Reason: {e}\")\n",
    "        return False\n",
    "\n",
    "is_onnx_model_valid(\"log_tempcnn/tempcnn_py_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ea344",
   "metadata": {},
   "source": [
    "Evaluation on the FRH04 Region of the trained PyTorch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "frh04 = BreizhCrops(region=\"frh04\", root=DATA_PATH, level=LEVEL, preload_ram=PRELOAD_RAM)\n",
    "model.load_state_dict(torch.load(\"log_tempcnn/tempcnn_py_model.pt\",map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038accd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_true, field_id = frh04[4005]  \n",
    "x = x.unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(x)  \n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1).item()\n",
    "print(f\"Field ID: {field_id}\")\n",
    "print(f\"True Class Index: {y_true} → {frh04.classname[y_true]}\")\n",
    "print(f\"Predicted Class Index: {predicted_class} → {frh04.classname[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cab434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "conf_per_class = defaultdict(list)\n",
    "\n",
    "for i in range(len(frh04)):\n",
    "    x, y_true, field_id = frh04[i]\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        y_pred = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "\n",
    "\n",
    "    y_true_all.append(y_true)\n",
    "    y_pred_all.append(y_pred)\n",
    "    conf_per_class[y_pred].append(confidence)\n",
    "\n",
    "# Classification report\n",
    "target_names = frh04.classname\n",
    "print(\" Python Classification Report - PyTorch : \")\n",
    "print(classification_report(y_true_all, y_pred_all, target_names=target_names,zero_division=0))\n",
    "\n",
    "# Average confidence per predicted class\n",
    "print(\"\\n Python Average Confidence per Predicted Class - PyTorch: \")\n",
    "for class_idx, confidences in conf_per_class.items():\n",
    "    avg_conf = np.mean(confidences)\n",
    "    print(f\"{class_idx:>2} ({frh04.classname[class_idx]:<15}): {avg_conf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cbf4c",
   "metadata": {},
   "source": [
    "PyTorch ONNX Evaluation on the FRH04 Region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 1\n",
    "sess_options.inter_op_num_threads = 1\n",
    "ort.set_default_logger_severity(2)\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    \"log_tempcnn/tempcnn_py_model.onnx\",\n",
    "    sess_options=sess_options,\n",
    "    providers=providers\n",
    ")\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "conf_per_class = defaultdict(list)\n",
    "\n",
    "for i in range(len(frh04)):\n",
    "    x, y_true, _ = frh04[i]\n",
    "    x_np = x.unsqueeze(0).numpy().astype(np.float32)  \n",
    "    log_probs = session.run([output_name], {input_name: x_np})[0][0] \n",
    "    probs = np.exp(log_probs)\n",
    "    y_pred = int(np.argmax(probs))\n",
    "    confidence = float(np.max(probs))\n",
    "    y_true_all.append(y_true)\n",
    "    y_pred_all.append(y_pred)\n",
    "    conf_per_class[y_pred].append(confidence)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n Python Classification Report - ONNX:\")\n",
    "print(classification_report(\n",
    "    y_true_all,\n",
    "    y_pred_all,\n",
    "    target_names=frh04.classname,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "#  Average Confidence per Predicted Class\n",
    "print(\"\\n Python Average Confidence per Predicted Class - ONNX:\")\n",
    "for class_idx, confs in conf_per_class.items():\n",
    "    avg_conf = np.mean(confs)\n",
    "    class_name = frh04.classname[class_idx]\n",
    "    print(f\"{class_idx:>2} ({class_name:<20}): {avg_conf:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f516b",
   "metadata": {},
   "source": [
    "Flux ONNX Evaluation on the FRH04 Region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 1\n",
    "sess_options.inter_op_num_threads = 1\n",
    "ort.set_default_logger_severity(2)\n",
    "\n",
    "providers = (\n",
    "    [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "    if \"CUDAExecutionProvider\" in ort.get_available_providers()\n",
    "    else [\"CPUExecutionProvider\"]\n",
    ")\n",
    "# Load Julia ONNX model\n",
    "session = ort.InferenceSession(\n",
    "    \"notebooks/tempcnn_julia_batch.onnx\",\n",
    "    sess_options=sess_options,\n",
    "    providers=providers\n",
    ")\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)  \n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=-1, keepdims=True)\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "conf_per_class = defaultdict(list)\n",
    "\n",
    "for i in range(len(frh04)):\n",
    "    x, y_true, _ = frh04[i]\n",
    "    x_np = x.unsqueeze(0).numpy().astype(np.float32)  \n",
    "    x_np = np.transpose(x_np, (0, 2, 1)).copy() \n",
    "    logits = session.run([output_name], {input_name: x_np})[0][0]  \n",
    "    probs = softmax(logits)\n",
    "    y_pred = int(np.argmax(probs))\n",
    "    confidence = float(np.max(probs))\n",
    "    y_true_all.append(y_true)\n",
    "    y_pred_all.append(y_pred)\n",
    "    conf_per_class[y_pred].append(confidence)\n",
    "\n",
    "#  Classification Report\n",
    "print(\"\\n Julia Classification Report - ONNX:\")\n",
    "print(classification_report(\n",
    "    y_true_all,\n",
    "    y_pred_all,\n",
    "    target_names=frh04.classname,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "#  Average Confidence per Predicted Class\n",
    "print(\"\\n Julia Average Confidence per Predicted Class - ONNX:\")\n",
    "for class_idx, confs in conf_per_class.items():\n",
    "    avg_conf = np.mean(confs)\n",
    "    class_name = frh04.classname[class_idx]\n",
    "    print(f\"{class_idx:>2} ({class_name:<20}): {avg_conf:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
